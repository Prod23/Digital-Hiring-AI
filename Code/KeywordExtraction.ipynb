{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUR9krzwHsNM",
        "outputId": "9e1fe735-e375-41e6-ef54-0d36aa3cd25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/faceDetection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtAY_KlNHxoL",
        "outputId": "538146af-8025-4138-ce54-d1d75794221a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1fuO6JO_pgGNTEhJEyY2vibemgT5zsv8r/faceDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjZdQ0OmMgar",
        "outputId": "865ac36d-fb0f-4653-c0e7-9cb5537ec0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PyPDF2 import PdfReader\n",
        "import re\n",
        "pdf_file_path='/content/drive/MyDrive/faceDetection/AI Intern- Job Description.pdf'\n",
        "def extract_text_from_pdf(pdf_file_path):\n",
        "    text = \"\"\n",
        "    pdf_reader = PdfReader(pdf_file_path)\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text()\n",
        "        text_without_escapes = re.sub(r'\\n', ' ', text)\n",
        "    return (text_without_escapes)\n",
        "text_without_escapes=extract_text_from_pdf(pdf_file_path)"
      ],
      "metadata": {
        "id": "-F7UMwhUMjiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"output.txt\"\n",
        "\n",
        "# Open the file in write mode and write the string content\n",
        "with open(file_path, \"w\") as text_file:\n",
        "    text_file.write(text_without_escapes)\n",
        "\n",
        "print(f\"String content has been written to {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfvvnbeBPMjA",
        "outputId": "4f050c29-568b-42f2-9400-09ec642075f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String content has been written to output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-trained FastText model (smaller and faster to download)\n",
        "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n"
      ],
      "metadata": {
        "id": "z288jYLjRfZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7f5466-f4e6-45c9-cf50-8e3653341803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.2% 950.8/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of keywords\n",
        "keywords = [\n",
        "    \"Associate\",\n",
        "    \"AI\",\n",
        "    \"Engineer\",\n",
        "    \"Hyderabad\",\n",
        "    \"Full Time\",\n",
        "    \"Computer Vision\",\n",
        "    \"Image Processing\",\n",
        "    \"Data processing\",\n",
        "    \"PyTorch\",\n",
        "    \"TensorFlow\",\n",
        "    \"Python\",\n",
        "    \"Problem solving\",\n",
        "    \"Machine Learning\",\n",
        "    \"Model Versioning\",\n",
        "    \"Deployment\",\n",
        "    \"Cloud Deployment\",\n",
        "    \"NLP\",\n",
        "    \"LLM\",\n",
        "    \"Text annotation\",\n",
        "    \"Information Extraction\",\n",
        "    \"Project Lead\",\n",
        "    \"Deep Learning\",\n",
        "    \"Machine Learning\",\n",
        "    \"ANN\",\n",
        "    \"CNN\",\n",
        "    \"RNN\",\n",
        "    \"Computer Science\"\n",
        "]\n",
        "\n",
        "# Read the text from a .txt file and use it as a document\n",
        "\n",
        "output_txt = \"\"\n",
        "with open(\"/content/drive/MyDrive/Techolution Final/one.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    output_txt = file.read()\n",
        "# Define the corpus of documents (including the content of document1.txt)\n",
        "corpus = [\n",
        "    output_txt\n",
        "\n",
        "    # Add more documents as needed\n",
        "]\n",
        "\n",
        "# Function to calculate cosine similarity\n",
        "def calculate_similarity(query, document):\n",
        "    query_vector = np.mean([fasttext_model[word] for word in query.split() if word in fasttext_model], axis=0)\n",
        "    document_vector = np.mean([fasttext_model[word] for word in document.split() if word in fasttext_model], axis=0)\n",
        "\n",
        "    # Check for NaN values or empty vectors\n",
        "    if np.isnan(query_vector).any() or np.isnan(document_vector).any() or np.count_nonzero(query_vector) == 0 or np.count_nonzero(document_vector) == 0:\n",
        "        return 0.0  # Return a similarity of 0 for empty or NaN vectors\n",
        "\n",
        "    return cosine_similarity([query_vector], [document_vector])[0][0]\n",
        "\n",
        "# Perform semantic search for each keyword\n",
        "results = {}\n",
        "final_scores=[]\n",
        "for keyword in keywords:\n",
        "    keyword_results = []\n",
        "    for document in corpus:\n",
        "        similarity = calculate_similarity(keyword, document)\n",
        "        final_scores.append(similarity)\n",
        "        keyword_results.append((document, similarity))\n",
        "    keyword_results.sort(key=lambda x: x[1], reverse=True)\n",
        "    results[keyword] = keyword_results\n",
        "\n",
        "# Print search results for each keyword\n",
        "for keyword, keyword_results in results.items():\n",
        "    print(f\"Results for '{keyword}':\")\n",
        "    for i, (document, similarity) in enumerate(keyword_results, start=1):\n",
        "        #print(f\"{i}. Document: {document}\")\n",
        "        print(f\"   Similarity: {similarity:.4f}\")\n",
        "final_scores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHL6-8v4IGzo",
        "outputId": "74ba8013-ec6a-4337-9c84-686bcef93e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 'Associate':\n",
            "   Similarity: 0.3683\n",
            "Results for 'AI':\n",
            "   Similarity: 0.2876\n",
            "Results for 'Engineer':\n",
            "   Similarity: 0.3319\n",
            "Results for 'Hyderabad':\n",
            "   Similarity: 0.3498\n",
            "Results for 'Full Time':\n",
            "   Similarity: 0.4602\n",
            "Results for 'Computer Vision':\n",
            "   Similarity: 0.3914\n",
            "Results for 'Image Processing':\n",
            "   Similarity: 0.3293\n",
            "Results for 'Data processing':\n",
            "   Similarity: 0.4716\n",
            "Results for 'PyTorch':\n",
            "   Similarity: 0.0000\n",
            "Results for 'TensorFlow':\n",
            "   Similarity: 0.4142\n",
            "Results for 'Python':\n",
            "   Similarity: 0.3447\n",
            "Results for 'Problem solving':\n",
            "   Similarity: 0.5452\n",
            "Results for 'Machine Learning':\n",
            "   Similarity: 0.3783\n",
            "Results for 'Model Versioning':\n",
            "   Similarity: 0.3672\n",
            "Results for 'Deployment':\n",
            "   Similarity: 0.2922\n",
            "Results for 'Cloud Deployment':\n",
            "   Similarity: 0.3711\n",
            "Results for 'NLP':\n",
            "   Similarity: 0.2589\n",
            "Results for 'LLM':\n",
            "   Similarity: 0.0907\n",
            "Results for 'Text annotation':\n",
            "   Similarity: 0.4394\n",
            "Results for 'Information Extraction':\n",
            "   Similarity: 0.4094\n",
            "Results for 'Project Lead':\n",
            "   Similarity: 0.4554\n",
            "Results for 'Deep Learning':\n",
            "   Similarity: 0.4240\n",
            "Results for 'ANN':\n",
            "   Similarity: 0.2011\n",
            "Results for 'CNN':\n",
            "   Similarity: 0.3341\n",
            "Results for 'RNN':\n",
            "   Similarity: -0.0054\n",
            "Results for 'Computer Science':\n",
            "   Similarity: 0.3793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36831206,\n",
              " 0.28758895,\n",
              " 0.33191413,\n",
              " 0.3497728,\n",
              " 0.4602051,\n",
              " 0.39140132,\n",
              " 0.3292668,\n",
              " 0.4715935,\n",
              " 0.0,\n",
              " 0.41417143,\n",
              " 0.34472322,\n",
              " 0.545168,\n",
              " 0.3782583,\n",
              " 0.3671786,\n",
              " 0.29216093,\n",
              " 0.37113458,\n",
              " 0.25885755,\n",
              " 0.09069754,\n",
              " 0.43937987,\n",
              " 0.40938857,\n",
              " 0.45541224,\n",
              " 0.4240331,\n",
              " 0.3782583,\n",
              " 0.20107263,\n",
              " 0.33409515,\n",
              " -0.0053624706,\n",
              " 0.3793354]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = sum(final_scores) / len(final_scores)\n",
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibGnQ7UCP_1d",
        "outputId": "ce9de6e0-31a2-4f81-e9a0-d90bb1a18254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3199023271876353"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric_job_description = 0.3*mean\n",
        "Metric_job_description = mean"
      ],
      "metadata": {
        "id": "AuoxWK_eUz_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Leetcode Analysis\n"
      ],
      "metadata": {
        "id": "XObdXDoclP6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Define the URL\n",
        "url = \"https://leetcode-stats-api.herokuapp.com/f20202075\"\n",
        "\n",
        "# Make an HTTP GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON response into a Python dictionary\n",
        "    data = json.loads(response.text)\n",
        "\n",
        "    # Print the dictionary\n",
        "    print(data)\n",
        "\n",
        "else:\n",
        "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q_DUnPYlRfN",
        "outputId": "f47a8dae-c00d-44b2-abd8-69da185910b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'success', 'message': 'retrieved', 'totalSolved': 15, 'totalQuestions': 2851, 'easySolved': 9, 'totalEasy': 714, 'mediumSolved': 5, 'totalMedium': 1510, 'hardSolved': 1, 'totalHard': 627, 'acceptanceRate': 40.48, 'ranking': 2141114, 'contributionPoints': 326, 'reputation': 0, 'submissionCalendar': {'1685232000': 1, '1687046400': 3, '1688774400': 1, '1690934400': 1, '1691020800': 1, '1692230400': 4}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Easy_percent = data['easySolved']/data['totalEasy']\n",
        "Medium_percent = data['mediumSolved']/data['totalMedium']\n",
        "Hard_percent = data['hardSolved']/data['totalHard']\n",
        "rank = data['ranking']\n",
        "rank_weight = 0\n",
        "if(rank < 20000):\n",
        "    rank_weight = 1\n",
        "\n",
        "if(rank < 5000):\n",
        "    rank_weight = 2"
      ],
      "metadata": {
        "id": "jibyJW_bl49U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = Easy_percent*1 + Medium_percent*2 + Hard_percent*3 + rank_weight"
      ],
      "metadata": {
        "id": "vvw-xQmGmNNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3GxJnL8mQKQ",
        "outputId": "2d43a52a-cba0-45b6-91be-0055bd143b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.024012247568313425"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hcWd_SvtmTGK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}